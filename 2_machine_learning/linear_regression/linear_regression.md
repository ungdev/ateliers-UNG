
| âš™ï¸ / ğŸ§       | ğŸ·ï¸ / âŒğŸ·ï¸       | ğŸ”¢ / ğŸ—³ï¸       |
| -------------- | --------------- | --------------- |
| âš™ï¸ Machine Learning    | ğŸ·ï¸ Supervised Learning     | ğŸ”¢ RÃ©gression     |


<br>

## Sommaire
- [ğŸ‘¨â€ğŸ« PrÃ©sentation de la rÃ©gression linÃ©aire](#-rÃ©gression-linÃ©aire)
- [ğŸ› ï¸ Traitement des donnÃ©es](#ï¸-1-traitement-des-donnÃ©es-ou-presque)
- [ğŸ‘· Pratique de la rÃ©gression](#-2-pratique-de-la-rÃ©gression)

<br>

# ğŸ‘¨â€ğŸ« RÃ©gression linÃ©aire

Une rÃ©gression linÃ©aire, c'est quoi ?
ConcrÃ¨tement, c'est juste une fonction affine *(pour rappel, `f(x) = ax + b`...oui Ã§a remonte Ã  longtemps, on comprend)* qu'on essaie de faire passer au plus proche de nos points.

Par exemple, sur l'image ci-dessous, on considÃ¨re qu'on veut reprÃ©senter le prix d'une maison en fonction de sa surface. On a, en vert, des informations du marchÃ© (une maison Ã  5kâ‚¬ pour 5m2, une maison Ã  15kâ‚¬ pour 20m2...), et notre algorithme va tracer une droite qui approxime au mieux toutes ces valeurs (l'approximation est reprÃ©sentÃ©e par les points oranges).

<img src=img/linear_reg.png>

<br><br>

<details><summary><b> ğŸ’­ AppartÃ© importante : les mÃ©triques en IA </b></summary>
<br>
Pour calculer la performance du modÃ¨le, parce que c'est quand mÃªme mieux de savoir comment son modÃ¨le s'en sort, il existe tout un tas de mÃ©triques diffÃ©rentes qui veulent toute dire quelque chose de diffÃ©rent.

<br>

Fondamentalement, quand on travaille avec un modÃ¨le d'IA, le but final est de chercher Ã  rÃ©duire au maximum les diffÃ©rentes mÃ©triques d'erreur qu'on peut avoir.

<br>

Pour une rÃ©gression linÃ©aire, on utilise entre autres le calcul des **moindres carrÃ©s** *(MSE : moyenne des rÃ©sidus au carrÃ©, soit la diffÃ©rence entre la valeur rÃ©elle et prÃ©dite)*.

<img src=img/mse.png width="200">

<br>

Le but, c'est de **minimiser** cette valeur, et donc minimiser la fonction calculant l'erreur du modÃ¨le.

> *On utilisera plus tard la ***RMSE***, soit la racine de la MSE.*

L'autre mÃ©trique trÃ¨s simple d'utilisation et qu'on utilise partout, c'est *l'accuracy* ğŸ¯, soit la prÃ©cision du modÃ¨le. Tout simplement, c'est la proportion de bonnes prÃ©dictions du modÃ¨le.


### â¡ï¸ Quelles qu'elles soient, il faut **toujours** Ã©valuer les modÃ¨les sur des mÃ©triques mathÃ©matiques. 

</details>

<br>


## ğŸ› ï¸ 1. Traitement des donnÃ©es (ou presque)

Pour mettre en pratique une rÃ©gression linÃ©aire, on utilise un simple jeu de donnÃ©es sur le prix des maisons. Ce jeu de donnÃ©es prÃ©sente 19 dimensions, mais toutes les variables ne sont pas importantes Ã  conserver, car pas forcÃ©ment fortement corrÃ©lÃ©e au prix !
Pour Ã§a, on reprÃ©sente une matrice de corrÃ©lation, qui calcule le "score" de corrÃ©lation entre chacune des variables (on utilise le calcul de [Pearson](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)).

ConcrÃ¨tement, plus la case est claire, plus les valeurs sont corrÃ©lÃ©es (positivement, ou nÃ©gativement). On va donc exclure beaucoup de variables, comme `yr_renovated`, `sqft_lot` ou `condition`. On finit avec un jeu de donnÃ©es Ã  4 dimensions (pour l'exemple ici).

Si vous voulez traiter le jeu de donnÃ©es vous-mÃªme, vous pouvez le rÃ©cupÃ©rer sur Kaggle :
> [House Sales in King County, USA](https://www.kaggle.com/datasets/harlfoxem/housesalesprediction/data)

Sinon, voici le jeu de donnÃ©es prÃ©-traitÃ© :
> [SIMPLE_House Sales in King County, USA](kc_house_data.csv)

<br>

## ğŸ‘· 2. Pratique de la rÃ©gression 

Pour la rÃ©gression linÃ©aire, il faut tout d'abord installer les librairies nÃ©cessaires. Pour ce faire, exÃ©cutez la commande suivante :

```
pip install numpy scikit-learn pandas matplotlib
```

On va ensuite, dans un fichier Python, importer le jeu de donnÃ©es. Mettez votre `kc_house_data.csv` dans le mÃªme dossier que votre fichier Python, qu'on commencera avec le code ci-dessous :

```py
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

# Load the dataset
data = pd.read_csv('kc_house_data.csv')
```

Maintenant vous allez vite remarquer un problÃ¨me dans nos donnÃ©es : un nombre de chambres, Ã§a oscille entre 1 et 10 disons...alors que les *pieds* carrÃ©s, Ã§a oscille entre 200 et 4 000. Quand on calcule une fonction, avoir des ordres de grandeur si variÃ©s, Ã§a n'aide pas !
Pour remÃ©dier Ã  Ã§a, on utilise un `Scaler` qui va nous faire la mise Ã  l'Ã©chelle des valeurs tout seul, *c'est-y-pas magique* âœ¨.

Pour ce faire, on utilise ce code :
```py
y = data['price']   # y has the price, the data we try to predict
X = data[['bedrooms', 'bathrooms', 'sqft_living']]   # X has the data from which we try to predict the y data (price in this case)

scale = StandardScaler()   # Initialize the scaler
scale.fit(X)   # Fit it to the data
scaled_X = scale.transform(X)   # Transform the data according to the fitted scaler
```
<i>Dans une rÃ©gression linÃ©aire, Ã§a ne changera rien de scale les donnÃ©es, puisque diminuer l'Ã©chelle des donnÃ©es va simplement faire augmenter de maniÃ¨re inversement proportionnelle les coefficients de la rÃ©gression linÃ©aire, ce qui annulera l'effet du scaler. Mais par principe, on le fait Ã  chaque fois, Ã§a ne coÃ»te rien, et Ã§a peut Ã©viter des problÃ¨mes.</i>

<bt/>

La partie de mise en place faite, on s'occupe de l'algorithme.
En intelligence artificielle, il faut toujours **sÃ©parer les jeux de donnÃ©es** en deux groupes distincts :
- les donnÃ©es utilisÃ©es pour **entraÃ®ner** le modÃ¨le
- les donnÃ©es utilisÃ©es pour **tester** le modÃ¨le

Pendant sa phase d'apprentissage, on entraÃ®ne le modÃ¨le sur gÃ©nÃ©ralement **80%** du jeu de donnÃ©es, pour ensuite l'Ã©valuer sur **20%** du jeu de donnÃ©es, qu'il n'a jamais vu auparavant et qu'il n'utilisera pas pour amÃ©liorer son modÃ¨le. Cela permet de tester la robustesse, capacitÃ© Ã  gÃ©nÃ©raliser, du modÃ¨le face Ã  des donnÃ©es nouvelles.

<img src=img/test_train.png>

<br>

Pour sÃ©parer nos donnÃ©es, on utilise la fonction `test_train_split()` de la librairie `scikit-learn` qui fait tout pour nous, en utilisant une *seed* qui nous permet d'avoir un entraÃ®nement dÃ©terministe (*rÃ©sultat alÃ©atoire* = f(seed)) :
```py
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)   # test_size = proportion of dataset used for testing ; random_state = seed
```

Ceci Ã©tant fait, on peut dÃ©sormais initiliaser le modÃ¨le et l'entraÃ®ner... et pour une rÃ©gession linÃ©aire, pas de panique, on a encore des librairies pour nous mÃ¢cher le travail !
```py
# Instantiate a linear regression model
model = LinearRegression()

# This step lets the code run on its own all the training process. Right after, 'model' can be called anywhere as a pre-trained model
model.fit(X_train, y_train)
```

A prÃ©sent... Ã  vous de jouer ğŸ«µ. ComplÃ©tez cette ligne en remplaÃ§ant l'intÃ©rieur des arguments de `model.predict()`.
```py
# Predict using the trained model
y_pred = model.predict(///)
```

<details><summary>ğŸ’¡ Indice :</summary>
On cherche ici Ã  stocker les prÃ©dictions du modÃ¨le calculÃ©es sur les donnÃ©es de <strong>test</strong>. Donc, on fait une prÃ©diction sur <code>X_test</code> (et non pas <code>y_test</code>, car c'est la "rÃ©ponse" Ã  ce qu'on cherche : en donnant <code>X_test</code>, on approxime <code>y_test</code> et on rentre ces prÃ©dictions dans <code>y_pred</code>).

On a donc :
```py
y_pred = model.predict(X_test)
```
</details>

Etape importante ! Il faut maintenant calculer une mÃ©trique d'erreur, de performance, du modÃ¨le. Comme prÃ©sentÃ© en <a href='#1-rÃ©gression-linÃ©aire'>#1. RÃ©gression linÃ©aire</a>, on va ici utiliser la mÃ©thode des moindres carrÃ©s (et plus prÃ©cisÃ©ment, sa racine carrÃ©e) pour estimer l'erreur du modÃ¨le :
```py
# Calculate the root mean squared error
rmse = np.sqrt(np.mean((y_test - y_pred) ** 2))
print('Root Mean Squared Error:', rmse)
```
On obtient normalement une RMSE d'environ **272 466**. La RMSE dÃ©pendra toujours des donnÃ©es utilisÃ©es (ici, on travaille sur des prix avec de trÃ¨s grands ordres de grandeur).
Spoiler Alert : c'est quand mÃªme pas trÃ¨s bon comme score. Mais Ã§a s'explique par plusieurs facteurs :
- on utilise que 3 dimensions. C'est peu, trÃ¨s peu.
- la relation n'est pas forcÃ©ment linÃ©aire
- le jeu de donnÃ©es est biaisÃ© (la rÃ©partition des prix des maisons est inÃ©gale)

Ca n'empÃªche qu'on peut tout de mÃªme reprÃ©senter visuellement la performance de notre modÃ¨le. On a dÃ©cidÃ© de le reprÃ©senter autour d'une ligne droite : plus les points sont proches de la ligne rouge (X = Y), plus les prÃ©dictions sont bonnes.
```py
# Plot the predicted values against the actual values using a linear regression model
plt.scatter(y_pred, y_test)
# Plot a line x = y
plt.plot([0, max(max(y_test), max(y_pred))], [0, max(max(y_test), max(y_pred))], color='red')
plt.xlabel('Predicted Price')
plt.ylabel('Actual Price')
plt.title('Predicted Price vs Actual Price')
plt.show()
```

Si vous le souhaitez, pour amÃ©liorer les performances du modÃ¨le, vous pouvez tester avec + de variables. On a ainsi rapidement eu 22% d'erreur en moins...

> ğŸˆâ€â¬› Le code final est disponible dans ce dossier, sur le GitHub.

## Bravo ! ğŸ‰
Vous Ãªtes arrivÃ©s Ã  la fin de cette partie et avez rÃ©digÃ© votre premier algorithme de Machine Learning ğŸ‘.

Vous Ãªtes maintenant libre de suivre la suite des chapitres de l'atelier, que ce soit en Machine Learning ou Deep Learning, en vous rÃ©fÃ©rant au [sommaire](/README.md#-sommaire-des-ateliers)

Nous restons Ã  votre disposition pour la moindre question, donc n'hÃ©sitez pas ğŸ˜‰