
| ‚öôÔ∏è / üß†      | üè∑Ô∏è / ‚ùåüè∑Ô∏è       | üî¢ / üó≥Ô∏è       |
| -------------- | --------------- | --------------- |
| ‚öôÔ∏è Machine Learning    | üè∑Ô∏è Supervised Learning     | üî¢ R√©gression     |


<br>

# R√©gression lin√©aire

Une r√©gression lin√©aire, c'est quoi ?
Concr√®tement, c'est juste une fonction affine (pour rappel, `f(x) = ax + b`...oui √ßa remonte √† longtemps, on comprend) qu'on essaie de faire passer au plus proche de nos points.

Par exemple, sur l'image ci-dessous, on consid√®re qu'on veut repr√©senter le prix d'une maison en fonction de sa surface. On a, en vert, des informations du march√© (une maison √† 5k‚Ç¨ pour 5m2, une maison √† 15k‚Ç¨ pour 20m2...), et notre algorithme va tracer une droite qui approxime au mieux toutes ces valeurs.

<img src=img/linear_reg.png>

Pour calculer la performance du mod√®le, on utilise le calcul des **moindres carr√©s** (somme des r√©sidus au carr√©, soit la diff√©rence entre la valeur r√©elle et pr√©dite). Le but, c'est de **minimiser** cette valeur, et donc minimiser la fonction calculant l'erreur du mod√®le.
Fondamentalement, quand on travaille avec un mod√®le d'IA, le but final est de chercher √† r√©duire au maximum les diff√©rentes m√©triques d'erreur qu'on peut avoir : les moindres carr√©s repr√©sentent une m√©trique parmi tant d'autres.


## 1. Traitement des donn√©es (ou presque)

Pour mettre en pratique une r√©gression lin√©aire, on utilise un simple jeu de donn√©es sur le prix des maisons. Ce jeu de donn√©es pr√©sente 19 dimensions, mais toutes les variables ne sont pas importantes √† conserver, car pas forc√©ment fortement corr√©l√©e au prix !
Pour √ßa, on repr√©sente une matrice de corr√©lation, qui calcule le "score" de corr√©lation entre chacune des variables (on utilise le calcul de [Pearson](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)).

Concr√®tement, plus la case est claire, plus les valeurs sont corr√©l√©es (positivement, ou n√©gativement). On va donc exclure beaucoup de variables, comme `yr_renovated`, `sqft_lot` ou `condition`. On finit avec un jeu de donn√©es √† 4 dimensions (pour l'exemple ici).

Si vous voulez traiter le jeu de donn√©es vous-m√™me, vous pouvez le r√©cup√©rer sur Kaggle :
> [House Sales in King County, USA](https://www.kaggle.com/datasets/harlfoxem/housesalesprediction/data)

Sinon, voici le jeu de donn√©es pr√©-trait√© :
> [SIMPLE_House Sales in King County, USA](kc_house_data.csv)

## 2. Pratique de la r√©gression 

Pour la r√©gression lin√©aire, il faut tout d'abord installer les librairies n√©cessaires. Pour ce faire, ex√©cutez la commande suivante :

```
pip install numpy scikit-learn pandas matplotlib
```

On va ensuite, dans un fichier Python, importer le jeu de donn√©es. Mettez votre `kc_house_data.csv` dans le m√™me dossier que votre fichier Python, qu'on commencera avec le code ci-dessous :

```py
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

# Load the dataset
data = pd.read_csv('kc_house_data.csv')
```

Maintenant vous allez vite remarquer un probl√®me dans nos donn√©es : un nombre de chambres, √ßa oscille entre 1 et 10 disons...alors que les *pieds* carr√©s, √ßa oscille entre 200 et 4 000. Quand on calcule une fonction, avoir des ordres de grandeur si vari√©s, √ßa n'aide pas !
Pour rem√©dier √† √ßa, on utilise un `Scaler` qui va nous faire la mise √† l'√©chelle des valeurs tout seul, *c'est-y-pas magique* ‚ú®.

Pour ce faire, on utilise ce code :
```py
y = data['price']   # y has the price, the data we try to predict
X = data[['bedrooms', 'bathrooms', 'sqft_living']]   # X has the data from which we try to predict the y data (price in this case)

scale = StandardScaler()   # Initialize the scaler
scale.fit(X)   # Fit it to the data
scaled_X = scale.transform(X)   # Transform the data according to the fitted scaler
```


La partie de mise en place faite, on s'occupe de l'algorithme.
En intelligence artificielle, il faut toujours s√©parer les jeux de donn√©es en deux groupes distincts : les donn√©es utilis√©es pour entra√Æner le mod√®le, et les donn√©es utilis√©es pour tester le mod√®le : pendant sa phase d'apprentissage, on entra√Æne le mod√®le sur g√©n√©ralement **80%** du jeu de donn√©es, pour ensuite l'√©valuer sur **20%** du jeu de donn√©es, qu'il n'a jamais vu auparavant et qu'il n'utilisera pas pour am√©liorer son mod√®le. Cela permet de tester la robustesse, capacit√© √† g√©n√©raliser, du mod√®le face √† des donn√©es nouvelles.

Pour s√©parer nos donn√©es, on utilise la fonction `test_train_split` de la librairie `scikit-learn` qui fait tout pour nous, en utilisant une seed :
```py
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)   # test_size = proportion of dataset used for testing ; random_state = seed
```

Ceci √©tant fait, on peut d√©sormais initiliaser le mod√®le et l'entra√Æner... et pour une r√©gession lin√©aire, pas de panique, on a encore des librairies pour nous m√¢cher le travail !
```py
# Instantiate a linear regression model
model = LinearRegression()

# This step lets the code run on its own all the training process. Right after, 'model' can be called anywhere as a pre-trained model
model.fit(X_train, y_train)
```

A pr√©sent... √† vous de jouer ü´µ. Compl√©tez cette ligne en rempla√ßant l'int√©rieur des arguments de `model.predict()`.
```py
# Predict using the trained model
y_pred = model.predict(///)
```

<details><summary>üí° Indice :</summary>
On cherche ici √† stocker les pr√©dictions du mod√®le calcul√©es sur les donn√©es de <strong>test</strong>. Donc, on fait une pr√©diction sur <code>X_test</code> (et non pas <code>y_test</code>, car c'est la "r√©ponse" √† ce qu'on cherche : en donnant <code>X_test</code>, on approxime <code>y_test</code> et on rentre ces pr√©dictions dans <code>y_pred</code>).

On a donc :
```py
y_pred = model.predict(X_test)
```
</details>

Etape importante ! Il faut maintenant calculer une m√©trique d'erreur, de performance, du mod√®le. Comme pr√©sent√© en <a href='#1-r√©gression-lin√©aire'>#1. R√©gression lin√©aire</a>, on va ici utiliser la m√©thode des moindres carr√©s (et plus pr√©cis√©ment, sa racine carr√©e) pour estimer l'erreur du mod√®le :
```py
# Calculate the root mean squared error
rmse = np.sqrt(np.mean((y_test - y_pred) ** 2))
print('Root Mean Squared Error:', rmse)
```
On obtient normalement une RMSE d'environ **272 466**. La RMSE d√©pendra toujours des donn√©es utilis√©es (ici, on travaille sur des prix avec de tr√®s grands ordres de grandeur).
Spoiler Alert : c'est quand m√™me pas tr√®s bon comme score. Mais √ßa s'explique par plusieurs facteurs :
- on utilise que 3 dimensions. C'est peu, tr√®s peu.
- la relation n'est pas forc√©ment lin√©aire
- le jeu de donn√©es est biais√© (la r√©partition des prix des maisons est in√©gale)

Ca n'emp√™che qu'on peut tout de m√™me repr√©senter visuellement la performance de notre mod√®le. On a d√©cid√© de le repr√©senter autour d'une ligne droite : plus les points sont proches de la ligne rouge (X = Y), plus les pr√©dictions sont bonnes.
```py
# Plot the predicted values against the actual values using a linear regression model
plt.scatter(y_pred, y_test)
# Plot a line x = y
plt.plot([0, max(max(y_test), max(y_pred))], [0, max(max(y_test), max(y_pred))], color='red')
plt.xlabel('Predicted Price')
plt.ylabel('Actual Price')
plt.title('Predicted Price vs Actual Price')
plt.show()
```

Si vous le souhaitez, pour am√©liorer les performances du mod√®le, vous pouvez tester avec + de variables. On a ainsi rapidement eu 22% d'erreur en moins...
Le code final est disponible dans ce dossier, sur le GitHub.

